{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RunPassBot: Data Munging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to actually build a model, we first will need data. The genesis of this project was a dataset that was released on Kaggle; the 2015 play-by-play data. From this dataset I got the idea that a prediction could be made about the type of play that a team would call based on similar situations. I used the nflscrapR tool in R to pull the previous seasons, based on the fact that removing plays that were not run or pass reduced the dataset size past the point where I felt that any insights could be gained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import feather\n",
    "import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the datasets for the 2009-2015 seasons were placed in the /data/raw directory, in order to preserve data immutability; namely that the data will pass through a pipeline and be interacted with in memory, but the original files would stay the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_raw_data = '../data/raw/'\n",
    "path_to_processed_data = '../data/processed/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could open each file individually and the concat the datasets from there in a seperate step from each other. Instead we will use glob and the built-in os packages to open all the files, concat them into a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marktrovinger/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:2: DtypeWarning: Columns (26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "all_data_files = glob.glob(os.path.join(path_to_raw_data, \"*.csv\"))\n",
    "all_raw_dataframe = pd.concat(pd.read_csv(f) for f in all_data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/raw/season2009playby.csv',\n",
       " '../data/raw/season2010playby.csv',\n",
       " '../data/raw/season2011playby.csv',\n",
       " '../data/raw/season2012playby.csv',\n",
       " '../data/raw/season2013playby.csv',\n",
       " '../data/raw/season2014playby.csv',\n",
       " '../data/raw/season2015playby.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>GameID</th>\n",
       "      <th>Drive</th>\n",
       "      <th>qtr</th>\n",
       "      <th>down</th>\n",
       "      <th>time</th>\n",
       "      <th>TimeUnder</th>\n",
       "      <th>TimeSecs</th>\n",
       "      <th>PlayTimeDiff</th>\n",
       "      <th>...</th>\n",
       "      <th>Accepted.Penalty</th>\n",
       "      <th>PenalizedTeam</th>\n",
       "      <th>PenaltyType</th>\n",
       "      <th>PenalizedPlayer</th>\n",
       "      <th>Penalty.Yards</th>\n",
       "      <th>PosTeamScore</th>\n",
       "      <th>DefTeamScore</th>\n",
       "      <th>ScoreDiff</th>\n",
       "      <th>AbsScoreDiff</th>\n",
       "      <th>Season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46</td>\n",
       "      <td>2009-09-10</td>\n",
       "      <td>2009091000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15:00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68</td>\n",
       "      <td>2009-09-10</td>\n",
       "      <td>2009091000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14:53</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3593.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92</td>\n",
       "      <td>2009-09-10</td>\n",
       "      <td>2009091000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14:16</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3556.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>113</td>\n",
       "      <td>2009-09-10</td>\n",
       "      <td>2009091000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13:35</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3515.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>139</td>\n",
       "      <td>2009-09-10</td>\n",
       "      <td>2009091000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13:27</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3507.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        Date      GameID  Drive  qtr  down   time  TimeUnder  \\\n",
       "0          46  2009-09-10  2009091000      1    1   NaN  15:00       15.0   \n",
       "1          68  2009-09-10  2009091000      1    1   1.0  14:53       15.0   \n",
       "2          92  2009-09-10  2009091000      1    1   2.0  14:16       15.0   \n",
       "3         113  2009-09-10  2009091000      1    1   3.0  13:35       14.0   \n",
       "4         139  2009-09-10  2009091000      1    1   4.0  13:27       14.0   \n",
       "\n",
       "   TimeSecs  PlayTimeDiff  ...   Accepted.Penalty  PenalizedTeam  PenaltyType  \\\n",
       "0    3600.0           0.0  ...                  0            NaN          NaN   \n",
       "1    3593.0           7.0  ...                  0            NaN          NaN   \n",
       "2    3556.0          37.0  ...                  0            NaN          NaN   \n",
       "3    3515.0          41.0  ...                  0            NaN          NaN   \n",
       "4    3507.0           8.0  ...                  0            NaN          NaN   \n",
       "\n",
       "   PenalizedPlayer  Penalty.Yards  PosTeamScore  DefTeamScore ScoreDiff  \\\n",
       "0              NaN              0           0.0           0.0       0.0   \n",
       "1              NaN              0           0.0           0.0       0.0   \n",
       "2              NaN              0           0.0           0.0       0.0   \n",
       "3              NaN              0           0.0           0.0       0.0   \n",
       "4              NaN              0           0.0           0.0       0.0   \n",
       "\n",
       "  AbsScoreDiff Season  \n",
       "0          0.0   2009  \n",
       "1          0.0   2009  \n",
       "2          0.0   2009  \n",
       "3          0.0   2009  \n",
       "4          0.0   2009  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_raw_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe has 63 columns, many of which are unnecessary for the purposes of this project. The following list contains all of the columns that are not needed that we will drop from our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns_to_remove = ['Unnamed: 0', 'Date', 'GameID', 'Drive', 'time', 'TimeUnder', 'TimeSecs',\n",
    " \t\t\t\t\t'PlayTimeDiff', 'SideofField', 'yrdln','ydsnet','GoalToGo', 'FirstDown','posteam',\n",
    " \t\t\t\t\t'DefensiveTeam','desc','PlayAttempted','Yards.Gained','sp','Touchdown','ExPointResult',\n",
    " \t\t\t\t\t'TwoPointConv','DefTwoPoint','Safety','Passer','PassAttempt','PassOutcome','PassLength',\n",
    " \t\t\t\t\t'PassLocation','InterceptionThrown','Interceptor','Rusher','RushAttempt','RunLocation','RunGap',\n",
    " \t\t\t\t\t'Receiver','Reception','ReturnResult','Returner','Tackler1','Tackler2','FieldGoalResult',\n",
    " \t\t\t\t\t'FieldGoalDistance','Fumble','RecFumbTeam','RecFumbPlayer','Sack','Challenge.Replay',\n",
    " \t\t\t\t\t'ChalReplayResult','Accepted.Penalty','PenalizedTeam','PenaltyType','PenalizedPlayer',\n",
    " \t\t\t\t\t'Penalty.Yards','PosTeamScore','DefTeamScore','AbsScoreDiff','Season']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_raw_dataframe.drop(columns_to_remove, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to make sure that the dataframe is free of NaNs, as the model will choke on NaNs. But first, we need to know how many NaNs are present to see if it will have a negative impact on the number of data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_raw_dataframe.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having NaNs in the down field is not a big problem; a NaN in this field indicates events that we don't care about. We can easily drop these without a loss of precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_raw_dataframe.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we lost the NaNs from the dataset, we still need to remove the plays that aren't run or pass plays. First we will create a short list of plays we want to keep, and then filter out the plays that don't fit that category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_raw_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "play_list = ['Run', 'Pass']\n",
    "final_clean_dataset = all_raw_dataframe[all_raw_dataframe['PlayType'].isin(play_list)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see from the .head() command what our dataframe looks like now that we have cleaned it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_clean_dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_clean_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code for the project, I save the dataframe to a feather file, so I can keep the dtypes and any other useful pandas data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feather.write_dataframe(final_clean_dataset, path_to_processed_data+ 'clean_dataset.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RunPassBot: The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model that TPOT selected as the best is the Gradient Boosting Classifier. We will use that classifier for our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier(learning_rate=0.16, max_features=1.0, \n",
    "\t\t\t\t\t\t\t\t min_weight_fraction_leaf=1e-06, n_estimators=1000, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start training our model, we need to split the dataset into our test and training sets. We use scikit-learn's built in module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ['ScoreDiff', 'down', 'qtr', 'ydstogo', 'yrdline100']\n",
    "target = 'PlayType'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_clean_dataset['PlayType'] = final_clean_dataset['PlayType'].map({'Run' : 0, 'Pass': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(train_X, test_X, train_y, test_y) = train_test_split(final_clean_dataset[features], final_clean_dataset[target], test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time gbc.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time gbc.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbc.score(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tpot import TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tpot = TPOT(generations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tpot.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
